{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Z73-ngtgEQZU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from IPython.display import clear_output\n",
        "import cv2\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_width = new_height = 300"
      ],
      "metadata": {
        "id": "B2XZ619gG8X3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train images"
      ],
      "metadata": {
        "id": "dPLNUvY7aD0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = cv2.imread(\"/content/a1.jpg\")\n",
        "a1 = cv2.resize(a1, (new_width, new_height))\n",
        "a2 = cv2.imread(\"/content/a2.jpg\")\n",
        "a2 = cv2.resize(a2, (new_width, new_height))\n",
        "a3 = cv2.imread(\"/content/a3.jpg\")\n",
        "a3 = cv2.resize(a3, (new_width, new_height))\n",
        "a4 = cv2.imread(\"/content/a4.jpg\")\n",
        "a4 = cv2.resize(a4, (new_width, new_height))\n",
        "a5 = cv2.imread(\"/content/a5.jpg\")\n",
        "a5 = cv2.resize(a5, (new_width, new_height))\n",
        "a6 = cv2.imread(\"/content/a6.jpg\")\n",
        "a6 = cv2.resize(a6, (new_width, new_height))\n",
        "af = cv2.imread(\"/content/af.jpg\")\n",
        "af = cv2.resize(af, (new_width, new_height))"
      ],
      "metadata": {
        "id": "SiwacozCEwsw"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = cv2.imread(\"/content/p1.jpg\")\n",
        "p1 = cv2.resize(p1, (new_width, new_height))\n",
        "p2 = cv2.imread(\"/content/p2.jpg\")\n",
        "p2 = cv2.resize(p2, (new_width, new_height))\n",
        "p4 = cv2.imread(\"/content/p4.jpg\")\n",
        "p4 = cv2.resize(p4, (new_width, new_height))\n",
        "p7 = cv2.imread(\"/content/p7.jpg\")\n",
        "p7 = cv2.resize(p7, (new_width, new_height))\n",
        "p8 = cv2.imread(\"/content/p8.jpg\")\n",
        "p8 = cv2.resize(p8, (new_width, new_height))"
      ],
      "metadata": {
        "id": "rld_KWggJA1C"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = np.array([a1,p1,a2,p2,a3,p4,a4,p7,a5,p8,a6,af])\n",
        "train_lbls = np.array([0,1,0,1,0,1,0,1,0,1,0,0])"
      ],
      "metadata": {
        "id": "5iaz4LqiJ6mQ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test images"
      ],
      "metadata": {
        "id": "quGc-kMKaHxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_a = cv2.imread(\"/content/my_aadhar.jpg\")\n",
        "my_a = cv2.resize(my_a, (new_width, new_height))\n",
        "my_p = cv2.imread(\"/content/my_pan.jpg\")\n",
        "my_p = cv2.resize(my_p, (new_width, new_height))"
      ],
      "metadata": {
        "id": "46fLj77DWq8Y"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_imgs = np.array([my_a, my_p])\n",
        "test_lbls = np.array([0,1])"
      ],
      "metadata": {
        "id": "o5PAtpHMW2q6"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = np.array(['Aadhar','Pancard'])"
      ],
      "metadata": {
        "id": "aECqJC_QLLB1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network"
      ],
      "metadata": {
        "id": "dgmO3ze-aKmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional neural network is a regularized type of feed-forward neural network that learns feature engineering by itself via filters optimization. Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by using regularized weights over fewer connections. [Learn more](https://en.wikipedia.org/wiki/Convolutional_neural_network)"
      ],
      "metadata": {
        "id": "1_uDKOP1e3wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (300,300,3)), # if gray scale image is used then number of channels will be 1 not 3.\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(128, (3,3), activation = 'relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dense(2, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "cn7yfy6XK2FX"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Layer**:\n",
        "\n",
        "\n",
        "*   The core building block of a CNN\n",
        "*   Applies convolutional filters (also called kernels) to the input image to extract features.\n",
        "*   Captures local patterns and spatial relationships in the data.\n",
        "*   Each filter slides across the image and computes element-wise dot products, producing a feauture map.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M2b3KJHNfoWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch Normalization**\n",
        "\n",
        "\n",
        "*   Batch normalization (BN) is a technique used to normalize the activations of a neural network's layer across a mini-batch of training examples.\n",
        "*   It ensures that the mean activation is close to 0 and the standard deviation is close to 1.\n",
        "\n",
        "\n",
        "*   Benefits\n",
        "    1.   Faster convergence: BN helps in faster convergence during training by mitigating the vanishing/exploding gradient.\n",
        "    2.   Increased learning rates: It allows higher learning rates, making optimization more stable.\n",
        "    3.   Regularization Effect: BN has a slight regularization effect, reducing the risk of overfitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8wgVxfUjgiGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Max pooling layer**\n",
        "\n",
        "\n",
        "*   Downsampling operation: Max pooling is used to downsample feature maps in CNNs.\n",
        "*   Sliding window: A small window slides over the input feature map\n",
        "*   Pooling operation: Maximum value within each window is extracted.\n",
        "*   Downsampled Feature Map: Extracted max values form a new downsized feature map.\n",
        "*   Benefits: Translation invariance, reduces computation, and retains important features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MuYz9dtSiDSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropout layer**\n",
        "\n",
        "\n",
        "*   Regularization Technique: Dropout is a regularization technique in neural networks.\n",
        "*   Random Deactivation: During training, randomly selected neurons are \"dropped out\" or deactivated with a certain probability.\n",
        "*   Preventing Overfitting: Dropout helps prevent overfitting by reducing reliance on specific neurons.\n",
        "*   Network Variability: It forces the network to learn more robust and generalized features.\n",
        "*   Ensemble Effect: Dropout can be seen as training multiple models with different subsets of neurons, creating an ensemble effect.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wvbtKKMWi0OY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flat layer**\n",
        "\n",
        "\n",
        "*   The Flatten layer converts a multidimensional tensor into a one-dimensional vector.\n",
        "\n"
      ],
      "metadata": {
        "id": "8fGOAtrbjQp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dense layer**\n",
        "\n",
        "*   It consists of multiple neurons, each connected to every neuron from the previous layer.\n",
        "*   The Dense layer is responsible for capturing complex patterns and relationships in the data.\n",
        "*   It's often used as the final layer in a neural network for classification or regression tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "eGz6Mwp_jUSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation functions**\n",
        "\n",
        "\n",
        "*   ReLU: Rectified Linear Activation is an activation function that outputs the input if it's positive, otherwise outputs zero, enhancing learning speed and mitigating the vanishing gradient problem.\n",
        "*   Softmax: Softmax is an activation function that converts a vector of arbitrary values into a probability distribution, with each element indicating the likelihood of a class, suitable for multi-class classification tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "hcgRyqdoj8Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Ua6VYldXK4MC"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model.compile()** sets up the model for training by specifying the optimizer, loss function, and metrics for evaluation. The choice of these parameters impacts how the model's weights are updated and how its performance is assessed.\n",
        "\n",
        "**optimizer**: Specifies the optimization algorithm to update model weights during training. Common choices are: **adam** and **sgd**\n",
        "\n",
        "**loss**: Defines the loss function to measure the discrepancy between predicted and actual labels during training. For multi-class classification problems\n",
        "**sparse_categorical_crossentropy**: Appropriate when your labels are integers and not one-hot encoded.\n",
        "**metrics**: List of evaluation metrics to monitor during training and testing.\n",
        "**accuracy**: Measures the proportion of correctly predicted instances in the entire dataset.\n"
      ],
      "metadata": {
        "id": "pQCfJUGvkTXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_imgs, train_lbls, epochs = 5)"
      ],
      "metadata": {
        "id": "auAmWKZVLSoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model.fit()** trains the model on the training set. **epochs** is the number of iteration the model uses in this case 5 (which works for most models)."
      ],
      "metadata": {
        "id": "4F9daP8Vl05H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(test_imgs, test_lbls, verbose = 1)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq_gvKxrRt_I",
        "outputId": "5cbb7315-b97a-4304-a350-c789173d1d27"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 263ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the accuracy of the model on the test set."
      ],
      "metadata": {
        "id": "Wk1DT6PXmM3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(train_imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMFnhBjwSIQF",
        "outputId": "a5fbe6bc-84e1-417a-c813-418a05113e9b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 833ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions on the training images"
      ],
      "metadata": {
        "id": "VX3n1wbaaU4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(test_imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YToMoQ5kW-2T",
        "outputId": "db1188b9-be1b-4c31-e0ab-8ce773303780"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 131ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions on the test images"
      ],
      "metadata": {
        "id": "8PyjoO-ImYvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "  for n in range(0, test_imgs.shape[0]):\n",
        "    print(f\"Predicted: {class_names[np.argmax(pred[n])]}\")\n",
        "    if test_lbls[n] == 0:\n",
        "      print(f\"Actual: Aadhar\")\n",
        "    else:\n",
        "      print(f\"Actual: Pancard\")\n",
        "    print(\"=\"*20)"
      ],
      "metadata": {
        "id": "MCiTDhGLVBqv"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**np.argmax()** returns the index of the largest element in the array. In this case the largest number will be the most likely class."
      ],
      "metadata": {
        "id": "wlqqM_plmniU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUJICSAnVihA",
        "outputId": "382200b7-5f05-43e6-ae38-ac004ac1cf25"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: Aadhar\n",
            "Actual: Aadhar\n",
            "====================\n",
            "Predicted: Pancard\n",
            "Actual: Pancard\n",
            "====================\n"
          ]
        }
      ]
    }
  ]
}